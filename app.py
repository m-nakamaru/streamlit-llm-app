# --- app.py ã®å…ˆé ­ã« ---
import os, streamlit as st
if "OPENAI_API_KEY" in st.secrets and not os.getenv("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass
# -----------------------

# app.py â€”â€” èª²é¡Œè¦ä»¶ãƒ•ãƒ«å¯¾å¿œç‰ˆï¼ˆStreamlit Ã— LangChainï¼‰
import os
import streamlit as st

# --- Secretsï¼ˆCloudï¼‰ã‚’æœ€å„ªå…ˆã§ç’°å¢ƒå¤‰æ•°ã¸ ---
if "OPENAI_API_KEY" in st.secrets and not os.getenv("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# --- dotenv ã¯ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨ã€‚ç„¡ã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ã—ã¦è½ã¡ãªã„ ---
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

# --- LangChainï¼ˆ0.2ç³»ï¼‰ ---
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


# ========== UI ==========
st.set_page_config(page_title="LLM Expert App", page_icon="ğŸ¤–")
st.title("LLMæ©Ÿèƒ½ä»˜ãWebã‚¢ãƒ—ãƒªï¼ˆStreamlit Ã— LangChainï¼‰")

st.write(
    """
**ä½¿ã„æ–¹**
1. ä¸‹ã®ãƒ©ã‚¸ã‚ªã§ã€Œå°‚é–€å®¶ã®æŒ¯ã‚‹èˆã„ã€ã‚’é¸ã³ã¾ã™ã€‚  
2. ãƒ†ã‚­ã‚¹ãƒˆæ¬„ã«è³ªå•/ä¾é ¼ã‚’å…¥åŠ›ã—ã€**[å®Ÿè¡Œ]** ã‚’æŠ¼ã—ã¾ã™ã€‚  
3. ä¸‹éƒ¨ã«LLMã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚  
"""
)

persona = st.radio(
    "å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
    ["ç‰¹å®šè¡Œç‚ºç ”ä¿®ã®æŒ‡å°è€…ï¼ˆçœ‹è­·æ•™è‚²ï¼‰", "ç”ŸæˆAIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆPython/Streamlitï¼‰"],
    horizontal=True,
)

user_text = st.text_area(
    "è³ªå•ãƒ»ä¾é ¼å†…å®¹ï¼š",
    height=160,
    placeholder="ä¾‹ï¼‰å®Ÿç¿’è¨˜éŒ²ã®è©•ä¾¡è¦³ç‚¹ã‚’5ã¤ã«æ•´ç†ã—ã¦ï¼StreamlitÃ—LangChainã®æœ€å°ã‚³ãƒ¼ãƒ‰ã‚’æ•™ãˆã¦",
)


# ========== LLMå‘¼ã³å‡ºã—é–¢æ•°ï¼ˆè¦ä»¶ï¼šå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼†é¸æŠå€¤ã‚’å—ã‘ã¦å›ç­”æ–‡å­—åˆ—ã‚’è¿”ã™ï¼‰ ==========
def ask_llm(input_text: str, persona_choice: str) -> str:
    """é¸æŠã•ã‚ŒãŸå°‚é–€å®¶è¨­å®šã§LLMã«å•ã„åˆã‚ã›ã€å›ç­”ï¼ˆæ–‡å­—åˆ—ï¼‰ã‚’è¿”ã™ã€‚"""
    system_map = {
        "ç‰¹å®šè¡Œç‚ºç ”ä¿®ã®æŒ‡å°è€…ï¼ˆçœ‹è­·æ•™è‚²ï¼‰": (
            "ã‚ãªãŸã¯çœ‹è­·å¸«ã®ç‰¹å®šè¡Œç‚ºç ”ä¿®ã®æŒ‡å°è€…ã§ã™ã€‚"
            "é©å¿œåˆ¤æ–­/ç—…çŠ¶è©•ä¾¡/æ ¹æ‹ /å®Ÿæ–½å‰å¾Œã®è©•ä¾¡/æŒ¯ã‚Šè¿”ã‚Šã®è¦³ç‚¹ã§ã€"
            "è¦ç‚¹ã‚’ç®‡æ¡æ›¸ãã§ç°¡æ½”ã«ç¤ºã—ã€å°‚é–€ç”¨èªã«ã¯çŸ­ã„è£œè¶³ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚"
        ),
        "ç”ŸæˆAIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆPython/Streamlitï¼‰": (
            "ã‚ãªãŸã¯åˆå­¦è€…ã«æ•™ãˆã‚‹ç”ŸæˆAIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢/è¬›å¸«ã§ã™ã€‚"
            "Streamlit ã¨ LangChain ã®æœ€å°å®Ÿè£…ã€è¨­è¨ˆã®æ„å›³ã€è½ã¨ã—ç©´å›é¿ã‚’ã€"
            "çŸ­ã„ã‚³ãƒ¼ãƒ‰ä¾‹ã¨æ‰‹é †ã§å…·ä½“çš„ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        ),
    }
    system_msg = system_map.get(persona_choice, "ã‚ãªãŸã¯æœ‰èƒ½ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_msg + " å‡ºåŠ›ã¯æ—¥æœ¬èªã€‚å†—é•·è¡¨ç¾ã¯é¿ã‘ã€å®Ÿå‹™ã§å½¹ç«‹ã¤ç²’åº¦ã§ã€‚"),
            ("human", "{question}"),
        ]
    )

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)
    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"question": input_text})


# ========== å®Ÿè¡Œ ==========
run = st.button("å®Ÿè¡Œ", type="primary", disabled=not user_text.strip())

if run:
    if not os.getenv("OPENAI_API_KEY"):
        st.error(
            "OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.envï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰ã¾ãŸã¯ Cloud Secrets ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
    else:
        with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­..."):
            try:
                answer = ask_llm(user_text, persona)
                st.subheader("å›ç­”")
                st.write(answer)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")